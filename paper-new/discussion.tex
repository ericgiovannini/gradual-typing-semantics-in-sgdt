\section{Discussion}\label{sec:discussion}

\subsection{Related Work}

We give an overview of current approaches to proving graduality and discuss
their limitations where appropriate.

%%\subsubsection{From Static to Gradual}

The methods of Abstracting Gradual Typing \cite{garcia-clark-tanter2016} and the
formal tools of the Gradualizer \cite{cimini-siek2016} provide a way to derive
from a statically-typed language a language that satisfies graduality by
construction. The main downside to these approaches lies in their inflexibility:
since the process in entirely mechanical, the language designer must adhere to
the predefined framework.  Many gradually typed languages do not fit into either
framework, e.g., Typed Racket \cite{tobin-hochstadt06, tobin-hochstadt08}, and
the semantics produced is not always the desired one.
%
Furthermore, while these frameworks do prove graduality of the resulting
languages, they do not show the correctness of the equational theory, which is
equally important to sound gradual typing.


% \subsubsection{Graduality via Embedding-Projection Pairs}

A line of work by New, Licata and Ahmed
\cite{new-ahmed2018,new-licata18,new-licata-ahmed2019} develops an axiomatic
account of gradual typing and proves graduality by interpreting type precision
$c : A \ltdyn A'$ as an \emph{embedding-projection pair}, that is, a pure
embedding function $e : A \to A'$ and a possibly erroring projection $p : \li A'
\multimap \li A$ such that $p \circ e = \id$ and $e \circ p \ltdyn \id$. At
first glance, our model of precision looks different: it is a \emph{relation}
$\sem{c} : A \rel A'$ with a quasi-representability structure that gives us
something close to $e$ and $p$ in an embedding-projection pair. The relationship
between these models is that \emph{if} the relation were \emph{truly}
representable we would have that $e$ and $p$ form a \emph{Galois connection} $e
\circ p \ltdyn \id$ and $\id \ltdyn p \circ e$. However, we have dropped the
stronger property of retraction from our analysis in this work. With true
representability, the relation $c$ is \emph{uniquely determined} by the
embedding $e$, but since we only have quasi-representability, we need to keep
the relation around explicitly. So the extra complexity of managing explicit
relations is a cost of the intensional reasoning that guarded type theory
introduces. 
%
The line of work by New, Licata, and Ahmed involved both denotational methods
and operational logical relations approaches.
% The New-Licata-Ahmed axiomatic approach to gradual typing can be
% applied to both operational and denotational semantics.


% Later, New, Licata and Ahmed \cite{new-licata-ahmed2019} extended this axiomatic
% treatment from call-by-name to call-by-value as well by giving an axiomatic
% theory of type and term precision in call-by-push-value. 

% \subsubsection{Denotational and Operational Approaches}


%\subsubsection{Double-Categorical Semantics}

On the denotational side, New and Licata \cite{new-licata18} showed that the
graduality proof could be modeled using semantics in certain kinds of double
categories, which are categories internal to the category of categories. A
double category extends a category with a second notion of morphism, often a
notion of ``relation'' to be paired with the notion of functional morphism, as
well as a notion of functional morphisms preserving relations. In gradual
typing, the notion of relation models type precision and the squares model the
term precision relation.
%
% This approach was influenced by the semantics of parametricity using reflexive
% graph categories \cite{ma-reynolds,dunphythesis,reynoldsprogramme}: reflexive
% graph categories are essentially double categories without a notion of
% relational composition. In addition to capturing the notions of type and term
% precision, the double categorical approach allows for a \emph{universal
% property} for casts: upcasts are the \emph{universal} way to turn a relation
% arrow into a function in a forward direction and downcasts are the dual
% universal arrow.
%
The double-categorical framework serves as a foundation on which we base our
model construction in this paper. However, our model is not actually a double
category: the lack of transitivity of bisimilarity means that we cannot compose
extensional squares horizontally.

With the notion of abstract categorical model for gradual typing in hand,
denotational semantics is then the work of constructing concrete models that
exhibit the categorical construction. New and Licata \cite{new-licata18} present
such a model using categories of $\omega$-CPOs, and this model was extended by
Lennon-Bertrand, Maillard, Tabareau and Tanter \cite{gradualizing-cic} to prove
graduality of a gradual dependently typed calculus $\textrm{CastCIC}^{\mathcal
G}$. This domain-theoretic approach meets our criterion of being a semantic
framework for proving graduality, but suffers from the limitations of classical
domain theory: the inability to model viciously self-referential structures such
as higher-order extensible state and similar features such as runtime-extensible
dynamic types.

% Since these features are quite common in dynamically typed languages, we have
% developed in this work a new denotational framework that can be extended to
% model these type system features.

%\subsubsection{Step-Indexed Logical Relations Models}
% The standard alternative to domain theory that scales to essentially
% arbitrary self-referential definitions is \emph{step-indexing} or its
% synthetic form of \emph{guarded recursion}. 

On the operational side, a series of works
\cite{new-ahmed2018, new-licata-ahmed2019, new-jamner-ahmed19}
developed step-indexed logical relations models of gradually typed languages.
Unlike classical domain theory, such step-indexed techniques can scale to
essentially arbitrary self-referential definitions, which means they can model
higher-order store and runtime-extensible dynamic types
\cite{appelmcallester01,ahmed06,neis09,new-jamner-ahmed19}. However, as is
common with operational approaches, their proof developments are highly
repetitive and technical, with each development formulating a logical relation
from first-principles and proving many of the same tedious lemmas without
reusable mathematical abstractions.
%
%
% Additionally, the logical relations constructed to prove graduality in prior
% work \cite{new-ahmed2018,new-licata-ahmed2019,new-giovannini-licata-2022} suffer
% from technical complications of requiring two separate expression relations, one
% that counts steps on the left and the other on the right, and there is no
% analogue of this in our approach. However, using two expression relations allows
% some but not all transitive reasoning of term precision to be recovered. In the
% future we aim to explore if this approach is feasible in guarded semantics.
%
This is addressed somewhat by Siek and Chen \cite{siek-chen2021}, who give a
proof in Agda of graduality for an operational semantics using a \emph{guarded
logic of propositions} shallowly embedded in Agda. The guarded logic simplifies
the treatment of step-indexed logical relations, but the approach is still
fundamentally operational, and so the main lemmas of the work are still tied to
the particular operational syntactic calculus being modeled.
% A further advantage of the denotational approach is that it easily validates
% equational reasoning, not just graduality, and it is completely independent of
% any particular syntax of gradual typing.

Our work combines the benefits of both the denotational and step-indexed
approaches. We take as a starting point the denotational approach of New and
Licata, but we work with guarded type theory (a synthetic form of step-indexing)
rather than classical domain theory. As we have seen, in the guarded setting the compositional
theory of New-Licata breaks down. 
% when accounting for steps, the casts are no
% longer embedding-projection pairs, and we cannot carry out compositional
% reasoning on terms when those terms differ by an arbitrary unknown number of
% steps. 
Our work provides a novel refinement to their theory that allows for some
compositional reasoning to be recovered even in the guarded setting.

% \subsubsection{Gradual Dependent Types}
Eremondi \cite{Eremondi_2023} uses guarded type theory to
define a syntactic model for a gradually-typed source
language with dependent types. By working in guarded type theory, they are
able to give an exact semantics to non-terminating computations in a language
which is logically consistent, allowing for metatheoretic results about the
source language to be proven.
%
Similarly to our approach, they define a guarded lift monad to model potentially-
nonterminating computations and use guarded recursion to model the dynamic type.
However, they do not give a denotational semantics to term precision and it is unclear
how to prove graduality in this setting.
Their work includes a formalization of the syntactic model in Guarded Cubical Agda.

\subsection{Comparison of Denotational and Operational Approaches}
\eric{Some of this could be folded into the previous section, but this was one of the
big-picture questions from one of the reviewers.}

Denotational methods have several benefits compared to operational approaches,
and this carries over to the setting of gradual typing. First, denotational
methods are compositional and reusable, and allow for the use of existing
mathematical constructs and theorems, e.g., partial orderings, monads, etc,
while operational methods tend to require a significant amount of boilerplate
work to be done from scratch in each new development.
%
As a specific example of the compositional nature of our approach, the treatment
of the cast rules in our work is more compositional than in previous work using
operational semantics. Recall from Section \ref{sec:towards-relational-model}
that the cast rules needed for the proof of graduality build in composition of
type precision derivations. Rather than proving these from scratch in the model,
we are able to take as primitive simpler versions of the cast rules whose
validity in the model is easier to establish. Then from these simpler rules, we
derive the original ones using compositional reasoning.

A further advantage of the denotational approach is that it is completely
independent of any particular syntax of gradual typing. This allows for reuse
across multiple languages and makes it particularly straightforward to
accommodate additions to a language: adding support for a new type amounts to
defining a new object and extending the dynamic type accordingly. It also may be
possible to model alternative cast semantics by changing the definition of the
dynamic type and some type casts.
%
In contrast, operational methods are not as readily extensible, generally
requiring adding cases to the logical relations and the inductive proofs. In a
mechanized metatheory, this manifests as a ``copy-paste'' reusability rather than
the true code reuse one obtains with a denotational semantics.
%
An additional benefit to the denotational approach is that it is trivial to
establish the validity of the $\beta$ and $\eta$ principles, because they are
equalities in the semantics, whereas they require tedious manual proof in the
operational approach.

Finally, while we advocate for a denotational approach, the overall structure of
our semantics could be applied to an operational logical relations proof. For
example, there could be a step-indexed logical relation for strong error
ordering and one for weak bisimilarity, corresponding to the fact that objects
in our denotational model have an error ordering and a bisimilarity relation.
Then the precision rules for casts could be similarly validated using
perturbations as we did in this work.


\subsection{Mechanization}\label{sec:mechanization}
% Discuss Guarded Cubical Agda and mechanization efforts
In parallel with developing the theory discussed in this paper, we have
developed a partial formalization of our results in Guarded Cubical Agda
\cite{veltri-vezzosi2020}.
%
We formalized the major components of the definition of the concrete model
described in Section \ref{sec:concrete-relational-model}: predomains, error
domains, morphisms, relations, squares, using the guarded
features to define the free error domain, the lock-step error ordering, and weak
bisimilarity. We also formalized the no-go theorem from Section
\ref{sec:towards-relational-model}.

Building on these definitions, we formalized the notion of semantic
perturbations and push-pull structures as well as quasi-representable relations,
culminating in the definition of value and computation types and relations as
introduced in Section \ref{sec:concrete-relational-model}.
%
% culminating in the definition of value and computation types as predomains
% (resp. error domains) equipped with a monoid of syntactic perturbations with an
% interpretation homomorphism into the semantic perturbations. 
%
We constructed the predomain for the dynamic type via mixed induction and
guarded recursion, and defined its monoid of perturbations. We also defined the
relations $\inat$, $\itimes$, and $\iarr$, and proved that they are
quasi-representable.

% We have not yet formalized the constructions involving value and computation
% relations: showing that these relations compose, and defining the actions of the
% functors $\li$, $U$, $\times$, and $\arr$ on the relations. We have also not yet
% formalized the syntax-to-semantics translation.

% \max{need to say what's not formalized}

% We plan to formalize the construction of perturbations and 
% quasi-representable relations, but we have yet to decide
% whether to follow the approach we take in this work and define
% the abstract notion of intensional model and formalize the constructions in that setting,
% and then apply those abstract constructions to the concrete model.
% Alternatively, it may be better from a mechanization standpoint
% to carry out those abstract constructions explicitly in the concrete model,
% i.e., our representation of objects in the concrete model of predomains
% would include a field for the perturbations and our notion of relations
% would include fields for the push-pull property and quasi-representability.
% We leave this investigation to future work.

Lastly, we have formalized the big-step term semantics discussed in Section
\ref{sec:big-step-term-semantics} and the adequacy of the relational model
discussed in Section \ref{sec:adequacy}. This required us to add axioms about
clock quantification as well as axioms asserting the \emph{clock-irrelevance} of
booleans and natural numbers since as of this writing these axioms are not
built-in to Guarded Cubical Agda. These axioms are discussed in prior work on
guarded type theory \cite{atkey-mcbride2013, kristensen-mogelberg-vezzosi2022}.
The mechanization of adequacy also required us to formalize some essential
lemmas involving clocks and clock-irrelevance; we are considering later
refactoring these as part of a ``standard library'' for Guarded Cubical
Agda.
% \max{say these axioms are taken from prior work and cite that}

The remaining formalization work is the following:
\begin{enumerate}
    \item Showing that the functors $\times$ and $\arr$ preserve
    quasi-representability, which requires tedious reasoning about the Kleisli actions of
    $\times$ and $\arr$. These results are proved in the Appendix.
    \item Verifying the rules in the model corresponding to the equations for
    type precision derivations (see the bottom of Figure \ref{fig:gtlc-syntax}).
    These are also included in the Appendix.
    \item Formalizing the syntax-to-semantics translation.
\end{enumerate} 

\begin{comment}
% prove graduality in the syntax of 
% GTLC, which involves the construction of the abstract model described in 
% \ref{sec:concrete-model} and the extensional model with external dynamic 
% type. We also plan to formalize the adequacy result in \ref{sec:appendix-adequacy}.

% step-2 
Then we plan to construct the step-2 intensional model. Besides all the 
data in step-1, we need to include perturbations, functors $\times$, $\arr$, $U$, and $F$ that preserve 
perturbations and push/pull properties for all morphisms on value and 
computation types. Notice that for any object $A$ which has value type, 
we will take not only the monoid of perturbations $P^V_A$ and the monoid 
homomorphism $\ptbv_A : \pv_A \to \vf(A,A)$ on itself, but also $P^C_{F A}
$ and $\ptbe_{F A} : \pe_{F A} \to \ef(F A,F A)$ on $F A$, which have 
computation types. Similarly, for any computation object $B$, we will 
construct the perturbations on $U B$ besides the monoid $P^C_B$ and 
monoid homomorphism $\ptbe_B : \pe_B \to \ef(B,B)$. Also, for functors 
that preserves perturbations, we need to include the ones in the context 
of Kleisli category. For this part, we need to define the perturbation on 
not only the objects itself, but also the global lift and delay of objects, 
which requires us to provide each piece of supporting constructor. This step 
and futher steps towards to the model construction are still 
work-in-progress, but once it's finished, we will provide a complete 
framework which takes formalization on an explicit type and obtains an 
extensional model.

% step-3
In the step-3 intensional model, we will enhance it with 
quasi-representability. For any value relation $c : A \rel A'$, we need 
to show that there exists a left-representation structure for $c$ and a 
right-representation structure for $F\ c$. Correspondingly, for any 
computation relation $d : B \rel B'$, we will show there exists a 
right-representation structure for $d$ and a left-representation 
structure for $U\ d$. As we define the quasi-representability for value 
and computation relation, we will construct the quasi-representability on 
the function and product of the relation, which makes it necessary to 
have the dual version of quasi-representability.

% step-4 construct a concrete dynamic type and apply it to the abstract model
After defining the abstract model and its interface, we will model GTLC 
by providing explicit construction triples of dynamic type at each step, 
which includes defining Dyn as a predomain, its pure and Kleisli 
perturbation monoids, push/pull property for pure and Kleisli 
perturbation, as well as quasi-representability. The 
quasi-representability involves explicit rules which show that Nat is 
more precise than Dyn (Inj-Nat) and Dyn $\to$ Dyn is more precise than 
Dyn (Inj-Arr). Currently, we have formalized the concrete construction of 
Dyn in Cubical Agda and it was more challenging than expected because we 
define Dyn using the technique of guarded recursion and fixed point, which 
means that every time we analyze the case inside of Dyn, we need to unfold 
it and add corresponding proof. 

% adequacy
Besides the abstract model and its concrete construction on dynamic type, 
we will also formalize the adequacy result in \ref{sec:appendix-adequacy}, 
which involves clock quantification of the lift monad, the weak bisim 
relation, and the lock-step error ordering. In order to prove adequacy, 
we will first prove that the global lift of X is isomorphic to Delay(1 + X)
whether X is clock-irrelevant or not. Then, we aim to prove the equivalence 
between the global lock-step error ordering and the error ordering observed 
in Delay(1 + X) and equivalence between the global weak bisimilarity 
relation and the weak bisimilarity relation on Delay(1 + X). We have 
finished some prerequisite proofs on clock quantification and postulated 
some theorems on clock globalization.
\end{comment}



% \subsection{Synthetic Ordering}
% \max{cut this subsection if we need space}
% A key to managing the complexity of our concrete construction is in
% using a \emph{synthetic} approach to step-indexing rather than working
% analytically with presheaves. This has helped immensely in our ongoing
% mechanization in cubical Agda as it sidesteps the need to formalize
% these constructions internally. 
% %
% However, there are other aspects of the model, the bisimilarity and
% the monotonicity, which are treated analytically and are similarly
% tedious.
% %
% It may be possible to utilize further synthetic techniques to reduce
% this burden as well, and have all type intrinsically carry a notion of
% bisimilarity and ordering relation, and all constructions to
% automatically preserve them.
% %
% A synthetic approach to ordering is common in (non-guarded) synthetic
% domain theory and has also been used for synthetic reasoning for cost
% models \cite{fiore_1997,GrodinNSH24}.

\subsection{Future Work}

% \max{Expand on this, e.g. what some of the challenges might be and what would be reusable}
% In the future, we plan to apply our approach to give a denotational
% semantics for languages that feature higher-order state or
% runtime-extensible dynamic typing
% \cite{DBLP:journals/corr/abs-2210-02169} as well as richer type
% disciplines such as gradual dependent types and effect systems.

Our immediate next step is to apply our approach to give a denotational
semantics to gradually-typed languages with advanced type systems including
higher-order state or runtime-extensible dynamic typing
\cite{DBLP:journals/corr/abs-2210-02169}, as well as richer type disciplines
such as gradual dependent types and effect systems. This will involve adapting
prior operational models based on step-indexing (e.g.,
\cite{new-giovannini-licata-2022}) to the denotational setting and using guarded
type theory to obtain solutions to guarded domain equations as we did in this
work for the denotation of the dynamic type. The generality of our techniques
should allow for many of the constructions to be reused across different
languages. For instance, the free error domain construction can be easily
extended to model effects besides error and stepping
\cite{guarded-interaction-trees, probabilistic-fpc-guarded}.
We also aim to complete our Agda formalization and evolve it into a
reusable framework for mechanized denotational semantics of gradually-typed
languages.

This work has focused on the ``Natural'' semantics of casts , which
validate the full call-by-value $\eta$ laws for types, but other cast
semantics have been proposed such as eager
(\cite{herman-tomb-flanagan-2010}) and transient (\cite{transient})
cast semantics which trade off certain $\eta$ equalities for other
benefits such as early error detection or reduced runtime
overhead\cite{deepandshallowtypes,newlicataahmed19}. It would be a
good test of the generality of our semantic framework to see if it can
model these alternative semantics by adjusting the semantics of types
and casts, and providing proofs of weakened $\eta$ principles.

Additionally, while our focus in this work has been on reasoning up to
weak bisimilarity, the presence of explicit step counting in the model
could be viewed as a form of \emph{cost semantics}, where a runtime
cost is incurred from inspecting the dynamic type. This could possibly
be used to verify that cast optimizations such as space efficient
implementations \cite{herman-tomb-flanagan-2010} are not only
extensionally correct, but have a lower abstract cost.

% \max{Expand on this, e.g. what some of the challenges might be and what would be reusable}
% In the future, we plan to apply our approach to give a denotational semantics
% to gradually-typed languages that feature higher-order state or runtime-extensible dynamic
% typing \cite{DBLP:journals/corr/abs-2210-02169} as well as richer type
% disciplines such as gradual dependent types and effect systems. This will
% involve adapting prior operational models based on step-indexing (e.g.,
% \cite{new-giovannini-licata-2022}) to the denotational setting and using guarded
% type theory to obtain solutions to guarded domain equations as we did in this
% work for the denotation of the dynamic type. The generality of our techniques
% should allow for many of the constructions to be reused across different
% languages. For instance, the free error domain construction can be easily
% extended with additional cases to model effects besides error and stepping.
% Additionally, we aim to complete our Agda formalization and evolve it into a
% reusable framework for mechanized denotational semantics of gradually-typed
% languages.

%% to gradually-typed
%% languages with algebraic effects, building on prior work on gradual typing for effect handlers
%% \cite{greff}. In particular, that work proves graduality via a complicated step-indexed logical relation,
%% and we hope to prove their results by building a denotational model for GrEff.
%% This would serve as a step towards applying our techniques to prove graduality for languages
%% with other advanced features.

%% The extensional model we construct differs from the usual notion of extensional
%% model considered in prior work on gradual typing in that it lacks horizontal composition of squares.
%% We would like to clarify the relationship between our notion of model and prior extensional models,
%% with the aim of determining whether our approach could allow for the construction of such a model.
