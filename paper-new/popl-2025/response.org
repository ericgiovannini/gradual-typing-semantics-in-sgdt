We thank the reviewers for their helpful feedback. We agree that it
would be beneficial to provide more context comparing our work to
existing approaches to gradual typing and will incorporate this
discussion into the revision.

* Reviewer A's question about choice of axioms for type precision

  Reviewer A asks why we chose the particular set of axioms for type
  precision in the paper rather than the usual equivalent set of
  axioms used in prior work where reflexivity and transitivity are
  admissible.

  The reason behind this is somewhat technical, but the essential idea
  is that in our system, equivalent type precision derivations do not
  denote equal relations. They instead only denote relations that are
  /quasi-order-equivalent/, i.e., if two terms are related by one then
  they are related also by the other up to insertion of delays (see
  the statement of Theorem 5.12, line 1007).

  While the equivalent formulation is not sufficient for our purposes,
  there is a translation from the equivalent formulation's type
  precision derivations into our formulation that preserves type
  precision.


* Reviewer A confusion on lack of transitivity of weak bisimilarity

  Reviewer A notes that the lack of transitivity of our definition of
  weak bisimiarity for L℧ A is unexpected given the intuitive meaning
  of bisimilarity as being “equivalent when ignoring the number of
  reduction steps”.

  This is a good intuition for the usual coinductive notion of weak
  bisimilarity.  However, there is a subtle difference between
  coinductive bisimilarity and the guarded definition we employ for
  the free error domain. It is true that the "global" version of weak
  bisimilarity for the free error domain (defined using quantification
  over clocks) coincides with the usual coinductive definition for the
  Delay monad, and hence is transitive. By that point, however, we
  cannot apply guarded recursion to solve domain equations, so it is
  too late for it to be useful in our development.

  The formal explanation for why weak bisimiarity is not transitive
  is given by our no-go theorem: If it were transitive, then it follows
  from the theorem that it would be the trivial relation.  We can
  spell out part of the proof of the theorem for the specific case of
  weak bisimilarity, as follows:

  Suppose ≈ is transitive. Then we show that l ≈ fix θ for all l.
  Indeed, by Löb induction we assume that this holds later, and then
  we have

     (1)          (2)                (3)
    l ≈ θ (next l) ≈ θ (next (fix θ)) = fix θ

  where:
  (1) holds because weak bisimilarity is step-insensitive.
  (2) follows by definition of ≈ when both sides are θ, which says that the
  elements under the θ are related one time step later. This is precisely our
  Löb-induction hypothesis.
  (3) is the unfolding of a guarded fixpoint.

  And finally by transitivity, we conclude l ≈ fix θ.  A symmetric
  argument shows fix θ ≈ l for all l, and hence by transitivity we
  have l ≈ l for all l.
  
  
* Reviewer A's Q on why adequacy applies only to closed terms

  Reviewer A asks why we formulated our adequacy theorem for closed
  terms of type ℕ only, rather than giving a result for open terms of
  any type.

  We could formulate a version for open terms; it would say that
  if related closed terms are passed to our relation, then the outputs
  are related.  However, for our purposes we only need the result for
  closed terms, as is typical for adequacy results in previous work.
  

* Reviewer B's big-picture questions

  Reviewer B asks several questions about the broader relationship of
  our work to existing research on gradual typing. We address each of
  these below, and plan to incorporate these answers into the revised
  version of our paper.

** Novelty compared with New-Licata denotational model
   
  Our work takes as a starting point the denotational approach of New
  and Licata.  However, in the intensional (SGDT) setting, the
  compositional theory of New-Licata breaks down. Our work identifies
  a novel alternative theory to recover some amount of compositional
  analysis in a way that is compatible with intensional reasoning.

  The benefit to using SGDT over classical domain theory is that it
  allows for the solution of /arbitrary/ guarded domain equations,
  whereas in classical domain theory there are complex technical
  restrictions on what can be solved. In addition, work using
  classical domain theory for denotational semantics often requires an
  approach that is closely tied to the particular features of the
  language in question. Our model is extensible and we anticipate that
  future variations will be able to accommodate language features that
  classical domain theory is unable to model, e.g., higher-order store
  and dynamic type generation. Reviewer A requests an explanation for
  why classical domain theory is unable to handle these features; we
  refer to ___________ for the details.

  
 
** Benefits of the denotational approach for the gradual typing researcher

   Reviewer B asks about the benefits of the denotational approach for
   gradual typing researchers over the usual operational approach.
   The benefits in this setting are the same as the benefits of
   denotational semantics more broadly: Denotational methods are
   compositional and reusable, and allow for the use of existing
   mathematical constructs and theorems, e.g., partial orderings,
   monads, etc. This allows for a more structural approach where the
   term semantics is an ordinary call-by-push-value semantics.  In
   contrast, operational methods tend to require a significant amount
   of boilerplate work to be done from scratch in each new
   development.

   As a specific example of the compositional nature of our approach,
   the treatment of the cast rules in our work is more compositional
   than in previous work using operational semantics. The cast rules
   needed for the proof of graduality build in composition of type
   precision derivations. Rather than proving these from scratch, we
   are able to take as primitive simpler versions of the cast rules
   that are easier to prove in the model. Then from these simpler
   rules, we derive the original ones using compositional reasoning.

   Our denotational approach identifies reusable structure and is
   independent of the particular syntax of the language.  This makes
   it particularly straightforward to accommodate additions to the
   language: adding support for a new type amounts to defining a new
   object and extending the dynamic type accordingly. In contrast, the
   operational semantics is not as readily extensible, generally
   requiring adding cases to the logical relations and the inductive
   proofs. Lastly, another benefit to the denotational approach is
   that it is easy to establish the validity of the β and η
   principles, because they are equalities in the semantics.

   We emphasize that, although the benefits of the denotational
   approach are clear, the results of our work are not confined to the
   denotational setting. Given that SGDT is a synthetic formulation of
   step-indexing, it should be possible to formulate a version of our
   model in the setting of step-indexed logical relations. For
   example, there would be a logical relation for strong error
   ordering and one for weak bisimilarity, corresponding to the fact
   that objects in our denotational model have an error ordering and a
   bisimilarity relation.

   
** Implications for operational semantics of gradual typing?

   Reviewer B asks whether our work has implications for the variety
   of design proposals for the operational semantics of gradual
   typing.  Prior work [1] has established that the combination of
   soundness of the equational theory and graduality places
   restrictions on the operational behavior of casts. For example,
   different cast semantics (e.g., shallow semantics) validate
   graduality but fail to satisfy the equational reasoning principles.

   Our framework is designed to extend to other gradual typing systems
   based on different cast semantics and validate that those systems
   satisfy the graduality property. In addition, we can leverage the
   intensional nature of our framework to compare the cost of
   different cast semantics in terms of the number of steps that the
   casts take. This is not relevant to the graduality theorem but is
   crucial for optimizations.  For instance, one should be able to
   show using our denotational semantics that the space-efficient
   formulation of casts are equivalent to the standard system, but
   that the cost of casts in the former system is less than that of
   the latter.

   [1]: Max S. New, Daniel R. Licata, and Amal Ahmed. 2019. Gradual
   Type Theory.

   
** New design principles?

   Reviewer B also asks whether our work sheds light on new design
   principles for gradually-typed languages. While this was not the
   focus of our work, our approach will help in the development of new
   designs for gradually-typed languages in that they can be justified
   using an extension of our semantics.

   Our work formalizes one particular system, but it should be
   possible to use our framework to formalize other systems to prove
   graduality and utilize the intensional nature of our model to
   compare their relative costs.

   For example, other cast semantics (e.g., shallow semantics)
   validate graduality but fail to satisfy the equational reasoning
   principles.  Our framework should still apply to prove graduality
   of these systems.
   
** What do we learn about gradual typing through this new lens?

   Although the application of our work is to semantics of gradual
   typing, the principal technical contribution is actually about how
   to reason compositionally in the step-indexed setting.  One major
   takeaway is that it is even possible to recover some amount of
   transitive reasoning in the intensional setting. The novel
   methodology of perturbations that enables us to do so may find
   applications in work applying guarded type theory to other domains.

   In addition, our work presents a new semantic model and methodology
   for mechanized metatheory of gradually-typed languages which we
   intend to extend to gradually-typed languages with advanced
   features such as effects and higher-order store.


   
* Reviewer C's weaknesses

  Reviewer C mentions that the semantics we develop in the paper is
  not applied to anything.

  We note that the equations for GTLC have been demonstrated in prior
  work to correspond to program optimizations. As mentioned, the η
  laws were shown valid implicitly by virtue of defining the
  denotational semantics.  Proving the retraction principle for our
  model will validate optimizations involving casts.  In this work we
  were focused on graduality, which does not require retraction.


