\section{Introduction}
  
% gradual typing, graduality
\subsection{Gradual Typing and Graduality}
In programming language design, there is a tension between \emph{static} typing
and \emph{dynamic} typing disciplines. With static typing, the code is
type-checked at compile time, while in dynamic typing, the type checking is
deferred to run-time. Both approaches have benefits and excel in different
scenarios, with static typing offering compile-time assurance of a program's
type safety and type-based reasoning principles that justify program
optimizations, and dynamic typing allowing for rapid prototyping of a codebase
without committing to fixed type signatures.
%
Most languages choose between static or dynamic typing and as a result,
programmers that initially write their code in a dynamically typed language need
to rewrite some or all of their codebase in a static language if they would like
to receive the benefits of static typing once their codebase has matured.

\emph{Gradually-typed languages} \cite{siek-taha06, tobin-hochstadt06} seek to
resolve this tension by allowing for both static and dynamic typing disciplines
to be used in the same codebase. These languages support smooth interoperability
between statically-typed and dynamically-typed styles, allowing the programmer to
begin with fully dynamically-typed code and \emph{gradually} migrate portions of the
codebase to a statically typed style without needing to rewrite the project in a
completely different language.

%Gradually-typed languages should satisfy two intuitive properties.
% The following two properties have been identified as useful for gradually typed languages.

\eric{This paragraph could be deleted}
%% In order for this to work as expected, gradually-typed languages should allow for
%% different parts of the codebase to be in different places along the spectrum from
%% dynamic to static, and allow for those different parts to interact with one another.
%% Moreover, gradually-typed languages should support the smooth migration from
%% dynamic typing to static typing, in that the programmer can initially leave off the
%% typing annotations and provide them later without altering the meaning of the program.
%% % Sound gradual typing
%% Furthermore, the parts of the program that are written in a dynamic
%% style should soundly interoperate with the parts that are written in a
%% static style.  That is, the interaction between the static and dynamic
%% components of the codebase should preserve, to the extent possible,
%% the guarantees made by the static types.  In particular, while
%% statically-typed code can error at runtime in a gradually-typed
%% language, such an error can always be traced back to a
%% dynamically-typed term that violated the typing contract imposed by
%% statically typed code. Further, static type assertions are sound in
%% the static portion, and should enable type-based reasoning and
%% optimization.

% Moreover, gradually-typed languages should allow for
% different parts of the codebase to be in different places along the spectrum from
% dynamic to static, and allow for those different parts to interact with one another.
% In a \emph{sound} gradually-typed language,
% this interaction should respect the guarantees made by the static types.

% Graduality property
One of the fundamental theorems for gradually typed languages is
\emph{graduality}, also known as the \emph{dynamic gradual guarantee},
originally defined by Siek, Vitousek, Cimini, and Boyland
\cite{siek_et_al:LIPIcs:2015:5031, new-ahmed2018}.
%
Informally, graduality says that migrating code from dynamical to
statical typing should only allow for the introduction of static or
dynamic type errors, and not otherwise change the behavior of the
program.
%
This is a way to capture programmer intuition that increasing type
precision corresponds to a generalized form of runtime assertions in
that there are no observable behavioral changes up to the point of the
first dynamic type error\footnote{once a dynamic type error is raised,
in languages where the type error can be caught, program behavior may
then further diverge, but this is typically not modeled in gradual
calculi.}.
%
Fundamentally, this property comes down to the behavior of
\emph{runtime type casts}, which implement these generalized runtime
assertions.

Additionally, gradually typed languages should offer some of the
benefits of static typing. While classical type soundness, that
well-typed programs are free from runtime errors, is not compatible
with runtime type errors, we can instead focus on \emph{type-based
reasoning}. For instance, while dynamically typed $\lambda$ calculi
only satisfy $\beta$ equality for their type formers, statically typed
$\lambda$ calculi additionally satisfy type-dependent $\eta$
properties that ensure that functions are determined by their behavior
under application and that pattern matching on data types
is safe and exhaustive.

\eric{One of the reviewers said this should be moved later in the intro, but I think it makes sense here.}
More concretely, consider a gradually typed language whose only
effects are gradual type errors and divergence. Then if we fix a
result type of natural numbers, a whole program semantics is a partial
function from closed programs to either natural numbers or errors:
\[ -\Downarrow : \{M \,|\, \cdot \vdash M : \nat \} \rightharpoonup \mathbb{N} \cup \{\mho\} \]
where $\mho$ is notation for a runtime type error. We write $M
\Downarrow n$ and $M\Downarrow \mho$ to mean this semantics is defined
as a number or error, and $M\Uparrow$ to mean the semantics is
undefined, representing divergence.
%
A well-behaved semantics should then satisfy several properties. First, it
should be \emph{adequate}: natural number constants should step to
themselves $n \Downarrow n$. Second, it should validate type based reasoning. To
formalize type based reasoning, we give a typed equational theory for
terms of the language $M \equiv N$ for when two terms should be
considered equivalent. Then we want to verify that the big step
semantics respects this equational theory: if closed programs $M \equiv
N$ are equivalent in the equational theory then they have the same
semantics, $M \Downarrow n \iff N \Downarrow n$ and $M\Uparrow \iff N
\Uparrow$ and $M \Downarrow \mho \iff N \Downarrow \mho$.
%
Lastly, the graduality property is defined by giving an
\emph{inequational} theory called term precision, where $M \ltdyn N$
roughly means that $M$ and $N$ have the same type erasure and $M$ has
at each point in the program a more precise/static type than $N$.
%
Then, the graduality property states that if $M \ltdyn N$ are whole
programs then $M$ must either have the same behavior as $N$ or error:
Either $M\Downarrow \mho$ or $M \Downarrow n $ and $N \Downarrow n$ or
$M \Uparrow $ and $N \Uparrow$\footnote{we use a slightly more complex
definition of this relation in our technical development below that is
classically equivalent but constructively weaker}.

\subsection{Denotational Semantics in Guarded Domain Theory}

Our goal in this work is to provide an \emph{expressive},
\emph{reusable}, \emph{compositional} semantic framework for defining
such well-behaved semantics of gradually typed programs.
%
Our approach to achieving this goal is to provide a compositional
\emph{denotational semantics}, mapping types to a kind of semantic
domain, terms to functions and relations such as term precision to
proofs of semantic relations between the denoted functions.
%
Since the denotational constructions are all syntax-independent, the
constructions we provide may be reused for similar languages. Since it
is compositional, components can be mixed and matched depending on
what source language features are present.

Providing a semantics for gradual typing is inherently complicated in
that it involves: (1) recursion and recursive types through the
presence of dynamic types, (2) effects in the form of divergence and
errors (3) relational models in capturing the graduality
property. Recursion and recursive types must be handled using some
flavor of domain theory. Effects can be modeled using monads in the
style of Moggi, or adjunctions in the style of
Levy\cite{moggi,levy}. Relational properties and their verification
lead naturally to the use of reflexive graph categories or double
categories\cite{reflgraphcats,doublecats}.

The only prior denotational semantics for gradual typing was given by
New and Licata and is based on a classical Scott-style \emph{domain
theory} \cite{new-licata18}. The fundamental idea is to equip
$\omega$-CPOs with an additional ``error ordering'' $\ltdyn$ which
models the graduality ordering, and for casts to arise from
\emph{embedding-projection pairs}. Then the graduality property
follows as long as all language constructs can be interpreted using
constructions that are monotone with respect to the error ordering.
%
This framework has the benefit of being compositional, and was
expressive enough to be extended to model dependently typed gradual
typing \cite{gradualizing-cic}.
%
\max{we should make clear that we don't yet model these perverse recursive features}
However, an approach based on classical domain theory has fundamental
limitations: domain theory is incapable of modeling certain perversely
recursive features of programming languages such as dynamic type tag
generation and higher-order references, which are commonplace in
real-world gradually typed systems as well as gradual calculi.
%
Our long-term goal is to develop a semantics that will scale up to these
advanced features, and so we begin with this work by departing from
classical domain theory.

The main denotational alternative to classical domain theory that can
successfully model these advanced features is \emph{guarded} domain
theory, which we adopt in this work. While classical domain theory is
based on modeling types as ordered sets with certain joins, guarded
domain theory is based on an entirely different foundations, sometimes
(ultra)metric spaces but more commonly as ``step-indexed sets'', i.e.,
objects in the \emph{topos of trees}
\cite{birkedal-mogelberg-schwinghammer-stovring2011}.  Such an object
consists of a family $\{X_n\}_{n \in \mathbb{N}}$ of sets along with
restriction functions $r_n : X_{n+1} \to X_n$ for all $n$.  (in
category theoretic terminology, these are presheaves on the poset of
natural numbers.)  We think a $\mathbb{N}$-indexed set as an infinite
sequence of increasingly precise approximations to the true type being
modeled.
%
Key to guarded domain theory is that there is an operator
$\triangleright$ on step-indexed sets called ``later''. In terms of
sequences of approximations, the later operator delays the
approximation by one step. Then the crucial axiom of guarded domain
theory is that any guarded domain equation $X \cong F(\triangleright
X)$ has a unique solution. This allows guarded domain theory to model
essentially \emph{any} recursive concept, with the caveat that the
recursion is \emph{guarded} by a later.

Since guarded domain theory only provides solutions to guarded domain
equations, there is no systematic way to convert a classical
domain-theoretic semantics to a guarded one.  Classical domain theory
has limitations in what it can model, but it provides \emph{exact}
solutions to domain equations when it applies. When adapting the
New-Licata approach to guarded domain theory, the presence of later in
the semantics makes it \emph{intensional}, unfolding the dynamic type
requires an observable computational step. For example, a function
that pattern matches on an element of the dynamic type and then
returns it unchanged is \emph{not} equal to the identity function,
because it ``costs'' a step to perform the pattern match.
%
This leads to the main departure of our semantics from the New-Licata
approach: while the New-Licata semantics equips $\omega$-CPOs with an
error ordering, we work with types equipped with not just an error
ordering but also a \emph{bisimilarity} relation that reflects when
elements differ only in the number of abstract computational steps
that they take.
%
% ERIC: This could be merged into the summary at the end of the section
The reason for requiring these two separate notions is that in the setting of
guarded domain theory, it is not possible to carry out transitive reasoning
while being oblivious to the number of steps the elements take. We make this
statement precise in \ref{sec:towards-relational-model}. To overcome this
limitation, we develop further changes to the core concepts of our semantics as
discussed in that section.

% Because bisimilarity, unlike equality, is not transitive in the guarded
% setting, this necessitates further changes to the core
% concepts of our semantics. These challenges are discussed in Section \ref{sec:towards-relational-model}.

\subsection{Synthetic Guarded Domain Theory}

While guarded domain theory can be presented analytically using
ultrametric spaces or the topos of trees, in practice it is
considerably simpler to work \emph{synthetically} by working in a
non-standard foundational system such as \emph{guarded type
theory}. In guarded type theory later is taken as a primitive
operation on types, and we take as an axiom that guarded domain
equations have a (necessarily unique) solution. The benefit of this
synthetic approach is that when working in the non-standard
foundation, we don't need to model an object language type as a
step-indexed set, but instead simply as a set, and object-language
terms can be modeled in the Kleisli category of a simple monad defined
using guarded recursion. Not only does this make on-paper reasoning
about guarded domain theory easier, it also enables a simpler avenue
to verification in a proof assistant. Whereas formalizing analytic
guarded domain theory would require a significant theory of presheaves
and making sure that all constructions are functors on categories of
presheaves, formalizing synthetic guarded domain theory can be done by
directly adding the later modality and the guarded fixed point
property axiomatically.
%
% \max{TODO: more here, specifically this is where we should talk about adequacy I think}

\max{it's confusing that this is the synthetic section but we switch back to external reasoning. Maybe move this to the previous section and revisit it here?}
Because the solutions we obtain working in guarded domain theory are constructed
as a sequence of increasingly better approximations, when we want to establish a
property that holds in the limit, we must reason about all finite
approximations. In the setting of the topos of trees, this manifests as the need
to consider \emph{global elements} of the presheaves, i.e., a family of elements
$x_i \in X_i$ compatible with the restriction maps. For example, consider the
set of programs that may take a computational step or return unit.\footnote{This example is adapted from \cite{mogelberg-paviotti2016}.} In the
topos of trees, we can model this set as the indexed family of sets $\{X_n\}_{n \in \mathbb{N}}$
where for each $n \ge 1$ we define $X_n = \{0,1,\dots,n-1, \bot\}$. Here, $i$ denotes a program that steps
$i$ times and then returns, and $\bot$ denotes a program that fails to terminate
in $n-1$ steps or fewer. For any fixed $n$, the set $X_n$ fails to distinguish a
program that takes $n$ steps and then terminates from a program that never
terminates. On the other hand, if we instead consider the denotation of a
program to be a global element of the presheaf $\{X_n\}_{n \in \mathbb{N}}$ -- a family of elements
$x_i \in X_i$ for all $i \in \mathbb{N}$ -- then the denotation of the diverging
program will be distinct from that of a program that terminates, regardless of
the number of steps it takes.

\max{shouldn't we say we use clock quantification?}
In the setting of synthetic guarded domain theory, this same idea applies. To
construct a global solution we must use an additional construct, e.g., the
$\square$ modality \cite{10.1007/978-3-319-08918-8_8}, whose semantics in the
topos of trees model is to compute the global elements of a presheaf. A related
approach involves objects known as \emph{clocks}, whereby
\emph{clock-quantification} \cite{atkey-mcbride2013} provides a means to obtain
a global solution.

\max{this next paragraph is a bit too mysterious}
This has important ramifications for defining an adequate denotational semantics
in guarded domain theory, as we seek to do in this paper: we do not want our
denotational semantics to conflate a diverging program with a program that fails
to terminate in sufficiently few steps. Thus, establishing adequacy of a
semantics in guarded domain theory will require a means of globalizing,
a point we will return to in Section \ref{sec:big-step-term-semantics}.


% For example, when establishing the adequacy of a semantics defined using
% guarded type theory, we must reason about all finite approximations.

% In this paper, we develop an adequate denotational semantics that satisfies
% graduality and soundness of the equational theory of cast calculi using
% synthetic guarded domain theory.  


\subsection{Contributions and Outline}

The main contribution of this work is a compositional denotational
semantics for gradually typed languages that validates $\beta\eta$
equality and satisfies a graduality theorem. A great deal of the work
has further been verified in Guarded Cubical Agda \cite{veltri-vezzosi2020}, 
demonstrating that the semantics is readily mechanizable.
We provide an overview of the mechanization effort, and what remains to be formalized,
in Section \ref{sec:mechanization}.

\begin{comment}
\begin{enumerate}
\item First, we give a simple concrete term semantics where we show
  how to model the dynamic type as a solution to a guarded domain equation.
\item Next, we identify where prior work on classical domain theoretic
  semantics of gradual typing breaks down when using guarded semantics
  of recursive types.
\item We develop a key new concept of \emph{syntactic perturbations},
  which allow us to recover enough extensional reasoning to model the
  graduality property compositionally.
\item We combine this insight together with an abstract categorical
  model of gradual typing using reflexive graph categories and
  call-by-push-value to give a compositional construction of our
  denotational model.
\item We prove that the resulting denotational model provides a
  well-behaved semantics as defined above by proving \emph{adequacy},
  respect for an equational theory and the graduality property.
\end{enumerate}
\end{comment}

The paper is laid out as follows:
\max{I think there's too much detail in this outline, especially parts 4 and 5. Can we instead expand those into the Intro?}
\begin{enumerate}
\item In Section \ref{sec:GTLC} we fix our input language, a fairly
  typical gradually typed cast calculus.
\item In Section \ref{sec:concrete-term-model} we develop a
  denotational semantics in synthetic guarded domain theory for the
  \emph{terms} of the gradual lambda calculus.  The model is adeqauate
  and validates the equational theory, but it does not satisfy
  graduality. We use this to introduce some of our main technical
  tools: modeling recursive types in guarded type theory and modeling
  effects using call-by-push-value.
\item In Section \ref{sec:towards-relational-model} we show where the
  New-Licata classical domain theoretic approach fails to adapt
  cleanly to the guarded setting and explore the difficulties of
  proving graduality in an intensional model.
  %
  % ... including the reason why we need to introduce weak bisimilarity.
  %
  The key technical issue is that reasoning principles that are simultaneously
  extensional \emph{and} compositional are not compatible with guarded domain
  theory (here, extensional means relating elements that differ only in the
  number of computational steps they take). We make this statement precise with
  a no-go theorem (Theorem \ref{thm:no-go}). In light of this result, to recover
  some amount of compositional reasoning we model the graduality ordering using
  a combination of two relations: a lock-step error ordering in which elements
  must take the same number of steps, and a weak bisimilarity relation where
  elements differing only in their stepping behavior are related.

  % As a result, we split the
  % graduality ordering into two relations: a strong error ordering in which
  % elements must take the same number of steps, and a weak bisimilarity relation
  % where elements differing only in their stepping behavior are related.
  
\item In Section \ref{sec:concrete-relational-model} we describe the
  construction of the model in detail. Key here is a notion of \emph{syntactic
  perturbations}, which allow us to encode the steps taken by a term in a form
  that we can manipulate. This allows us to recover enough extensional reasoning
  to model the graduality property compositionally.
  % Key here is a notion of \emph{syntactic
  % perturbation}, which give us a type-directed way of imposing delays on terms.
  The resulting model validates the axioms for type and term precision specified
  in Section \ref{sec:GTLC}. The final step is to prove that the model is
  \emph{adequate} for the graduality property: a closed term precision $M \ltdyn
  N : \nat$ has the expected semantics, i.e., that $M$ errors or $M$ and $N$
  have the same extensional behavior. We do so by extending the globalization
  techniques used in defining the big-step term model to account for the
  interpretation of term precision.
\item In Section \ref{sec:discussion} we discuss prior work on proving
  graduality, the partial mechanization of our results in Agda, and
  future directions for denotational semantics of gradual typing.
\end{enumerate}
