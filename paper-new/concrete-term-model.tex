\section{A Denotational Semantics for Types and Terms}\label{sec:concrete-term-model}

As a first step to giving a well-behaved semantics of GTLC, in this
section we define a simpler semantics that validates all of our
desired properties except for graduality: that is, it is adequate and
validates $\beta\eta$ equality. Our relational semantics will then be
a refinement of this simpler design. In the process we will introduce
some of the technical tools we will use in the refined semantics:
guarded type theory and call-by-push-value. While these tools can be
somewhat technical we emphasize that due to the use of synthetic
guarded domain theory, this initial semantics is essentially just a
``na\"\i ve'' denotational semantics of an effectful language arising
from a monad on sets. But since we are working in the non-standard
foundation of guarded type theory our notion of sets allows for the
construction of more sophisticated sets and monads than classical
logic allows.

% In Section \ref{sec:towards-relational-model}, we will discuss how to extend the
% denotational semantics to accommodate the type and term precision orderings. 
%
%necessitate the abstract components that are found in the definition of the model.

\subsection{Guarded Type Theory}\label{sec:guarded-type-theory}

% \max{TODO: discuss this wording with Eric. Are we working in guarded
%   type theory, SGDT or Ticked Cubical Type Theory in the informal work
%   in the paper?}
We begin with a brief overview of the background theory that we use in this work.
\emph{Synthetic guarded domain theory}, or SGDT for
short, is an axiomatic framework in which we can reason about non-well-founded
recursive constructions while abstracting away the specific details of
step-indexing that we would need to track if we were working analytically. This
allows us to avoid the tedious reasoning associated with traditional
step-indexing techniques. We provide a brief overview here; more details can be
found in \cite{birkedal-mogelberg-schwinghammer-stovring2011}.

SGDT offers a synthetic approach to domain theory that allows for guarded
recursion to be expressed syntactically via a type constructor $\later \colon
\type \to \type$ (pronounced ``later''). The use of a modality to express
guarded recursion was introduced by Nakano \cite{Nakano2000}.
%
Given a type $A$, the type $\later A$ represents an element of type $A$ that is
available one time step later. There is an operator $\nxt : A \to\, \later A$
that ``delays'' an element available now to make it available later. We will use
a tilde to denote a term of type $\later A$, e.g., $\tilde{M}$.

% TODO later is an applicative functor, but not a monad

There is a \emph{guarded fixpoint} operator
\[ \fix : \forall T, (\later T \to T) \to T. \]
That is, to construct a term of type $T$, it suffices to assume that we have
access to such a term ``later'' and use that to help us build a term ``now''.
This operator satisfies the axiom that $\fix f = f (\nxt (\fix f))$.
%
In particular, $\fix$ applies when type $T$ is instantiated to a proposition 
$P : \texttt{Prop}$; in that case, it corresponds to $\lob$-induction.

% Clocked Cubical Type Theory
\subsubsection{Ticked Cubical Type Theory}
% TODO motivation for Clocked Cubical Type Theory, e.g., delayed substitutions?

Ticked Cubical Type Theory \cite{mogelberg-veltri2019} is an extension of
Cubical Type Theory \cite{CohenCoquandHuberMortberg2017} that has an additional
sort called \emph{ticks}. Ticks were originally introduced in
\cite{bahr-grathwohl-bugge-mogelberg2017}. A tick $t : \tick$ serves as evidence
that one unit of time has passed. In Ticked Cubical Type Theory, the type
$\later A$ is the type of dependent functions from ticks to $A$. The type $A$ is
allowed to depend on $t$, in which case we write $\later_t A$ to emphasize the
dependence.

% TODO next as a function that ignores its input tick argument?

% TODO include a figure with some of the rules for ticks

The rules for tick abstraction and application are similar to those of ordinary
$\Pi$ types. A context now consists of ordinary variables $x : A$ as well as
tick variables $t : \tick$. The presence of the tick variable $t$ in context
$\Gamma, (t : \tick), \Gamma'$ intuitively means that the values of the
variables in $\Gamma$ arrive ``first'', then one time step occurs, and then the
values of the variables in $\Gamma'$ arrive.
%
The abstraction rule for ticks states that if in context $\Gamma, t : \tick$
the term $M$ has type $A$, then in context $\Gamma$ the term $\lambda t.M$ has
type $\later_t A$.
%
Conversely, if we have a term $M$ of type $\later A$, and we have available in
the context a tick $t' : \tick$, then we can apply the tick to $M$ to get a
term $M[t'] : A[t'/t]$. However, there is an important restriction on when we
are allowed to apply ticks: To apply $M$ to tick $t$, we require $M$ to be
well-typed in the prefix of the context occurring before the tick $t$. That is,
all variables mentioned in $M$ must be available before $t$. This ensures that
we cannot, for example, define a term of type $\later \laterhs A \to\, \laterhs
A$ via repeated tick application.
% TODO restriction on tick application
%
For the sake of brevity, we will also write tick application as $M_t$.
The constructions we carry out in this paper will take place in a guarded type
theory with ticks.
\subsection{A Call-by-push-value Model}

% TODO there aren't actually computation types in the syntax. They
% arise because we are embedding call-by-value into CBPV.

Our denotational model of GTLC must account for the fact that the
language is call-by-value with non-trivial effects (divergence and
errors).  To do this, we formulate the model using the categorical
structures of Levy's \emph{call-by-push-value}
\cite{levy99}. Call-by-push-value is a categorical model of effects
that is a refinement of Moggi's monadic semantics
\cite{MOGGI199155}. While Moggi works with a (strong) monad $T$ on a
category $\mathcal V$ of pure morphisms, call-by-push-value works
instead with a decomposition of such a monad into an adjunction
between a category $\mathcal V$ of ``value types'' and pure morphisms
and a category $\mathcal E$ of ``computation types'' and homomorphisms.
The monad $T$ on $\calV$ is decomposed into a left adjoint
$F : \calV \to \calE$ constructing the type $F A$ of computations that
return $A$ values and right adjoint $U : \calE \to \calV$
constructing the type $U B$ of values that are first-class suspended
computations of type $B$. The monad $T$ can then be reconstituted as
$T = UF$, but the main advantage is that many constructions on
effectful programs naturally decompose into constructions on
value/computation types. Most strikingly, the CBV function type $A
\rightharpoonup A'$ decomposes into the composition of three
constructions $U(A \to F A')$ where $\arr : \calV^{op} \times \calE
\to \calE$ is a kind of mixed kinded function type. This decomposition
considerably simplifies treatment of the CBV function
type. Additionally, prior work on gradual typing semantics has shown
that the casts of gradual typing are naturally formulated in terms of
pairs of a pure morphism and a homomorphism, as we explain below
\cite{new-licata-ahmed2019}.

For our simple denotational semantics, the category $\calV$ is simply
the category $\Set$ of sets and functions. Then because GTLC is
call-by-value, all types will be interpreted as objects of this
category, i.e., sets. More interesting are the computation
types. These will be interpreted in a category of sets equipped with
algebraic\footnote{The $\theta$ structure is not algebraic in the
strictest sense since it does not have finite arity.} structure with
morphisms being functions that are homomorphic in this structure.
This algebraic structure needs to model the effects present in our
language, in this case these are errors as well as taking
computational steps (potentially diverging by taking computational
steps forever).
%
We call these algebraic structures simple error domains to distinguish
them from the error domains we define later to model graduality:
\begin{definition}[Simple Error Domains]
  A (simple) error domain $B$ consists of
  \begin{enumerate}
  \item A carrier set $UB$
  \item An element $\mho_{B} : UB$ representing error
  \item A function $\theta_B : \laterhs UB \to UB$ modeling a computational step
  \end{enumerate}
  A homomorphism of error domains $\phi : B \multimap B'$ is a
  function $\phi : UB \to UB'$ that preserves $\mho$ and $\theta$, i.e.,
  $\phi(\mho_B) = \mho_{B'}$ and $\phi(\theta_{B}(\tilde{x})) =
  \theta_{B'}(\later (\phi(\tilde{x})))$.  Simple error domains and
  homomorphisms assemble into a category $\ErrDom$ with a forgetful
  functor $U : \ErrDom \to \Set$ taking the underlying set and
  function.
\end{definition}
Here is our first point where we utilize guarded type theory: rather
than simply being a function $UB \to UB$, the ``think'' map $\theta$
takes an element \emph{later}. This makes a major difference, because
the structure of a think map combined with the guarded fixpoint
operator allows us to define recursive elements of $UB$ in that any
function $f : UB \to UB$ has a ``quasi-fixed point'' $\textrm{qfix}(f)
= \fix(f \circ \theta_B)$ satisfying the quasi-fixed point property:
\[ \qfix(f) = f(\delta_B(\qfix f)) \]
where $\delta_B = \theta_B \circ \nxt$ is a map we call the ``delay''
map which trivially delays an element now to be available later.  As
an example, we can define $\Omega_B = \qfix(\id) : UB$, the
``diverging element'' that ``thinks forever'' in that $\Omega_B =
\delta_B(\Omega_B)$. We call this a ``quasi'' fixed point because it is
\emph{nearly} a fixed point except for the presence of the delay map
$\delta_B$, which is irrelevant from an extensional point of view
where we would prefer to ignore differences in the number of steps
that computations take.

% \max{move this}
% The functor $\arr : \Set^{op} \times \errdom \to \errdom$ is defined on objects
% as follows. Given a set $A$ and error domain $B$, $A \arr B$ is the error domain
% whose underlying set is the set of functions $A \to UB$. The error element is
% the constant error function, i.e., $\lambda x. \mho_B$. The map $\theta :
% (\laterhs (A \to UB)) \to (A \to UB)$ is defined by 
% $\theta(\tilde{f}) = \lambda x . \theta_B (\tilde{f}_t)$.
% %
% Given a morphism $f : A_o \to A_i$ and $\phi : B_i \to B_o$, the morphism $f
% \arr \phi : (A_i \arr B_i) \to (A_o \arr B_o)$ is given by pre-composing by $f$
% and post-composing by $\phi$.

Then to model effectful programs, we need to construct a left adjoint
$\li : \Set \to \ErrDom$ to $U$ which constructs the ``free error
domain'' on a set, which models an effectful CBV computation.
%% \subsection{The Lift + Error Monad}\label{sec:lift-monad}
We base the construction on the \emph{guarded
lift monad} described in \cite{mogelberg-paviotti2016}. Here, we augment the
guarded lift monad to accommodate the additional effect of failure.
\begin{definition}[Free error domain]
  For a set $A$, we define the (carrier of) \emph{free error domain} $U(\li A)$ as the unique solution to the guarded domain equation:
  \[ U(\li A) \cong A + 1\, + \laterhs U(\li A). \]
  For which we use the following notation for the three constructors:
  \begin{enumerate}
  \item $\eta \colon A \to U(\li A)$
  \item $\mho \colon U(\li A)$
  \item $\theta \colon \laterhs U(\li A) \to U(\li A)$
  \end{enumerate}
  Here $\mho, \theta$ provide the error domain structure for $\li A$,
  and this has the universal property of being free in that any
  function $f : U(\li A) \to UB$ uniquely extends to a homomorphism
  $f^\dagger : \li A \multimap B$ satisfying $Uf^\dagger \circ \eta =
  f$. In other words, the free error monad is left adjoint $\li \dashv
  U$ to the forgetful functor, with $\eta$ the unit of the adjunction.
  %
  We will write $\theta_t(\dots)$ to mean $\theta (\lambda t. \dots)$.
\end{definition}
%% %
%% Unless otherwise mentioned, all constructs involving $\later$ or $\fix$ are
%% understood to be with respect to a fixed clock $k$. So for the above, we really
%% have for each clock $k$ a type $\li^k A$ with respect to that clock.
%% %
%% Formally, the lift monad $\li A$ is defined as the solution to the guarded
%% recursive type equation
%% %
%
An element of $\li A$ should be viewed as a computation that can either (1)
return a value (via $\eta$), (2) raise an error and stop (via $\mho$), or (3)
take a computational step (via $\theta$).
%
The operation $f^\dagger$ can be defined by guarded recursion in the
apparent way, and proven to satisfy the freeness property by L\"ob
induction.
% It is instructive to give at least one example of a use of guarded recursion, so
% we show below how to define extend:
% TODO
%
%
%% Verifying that the monadic laws hold uses \lob-induction and is straightforward.

%% % TODO mention that error domains are algebras of the lift monad?
%% We observe that the guarded lift monad applied to a set $A$ is the underlying
%% set of the free error domain on $A$ $A$, i.e., we have $\li = UF$ where $F :
%% \Set \to \errdom$ and $U : \errdom \to \Set$ and $F \dashv U$. Given a set $A$
%% and an error domain $B$, the set of functions $A \to UB$ is naturally isomorphic
%% to the set of error domain morphisms $FA \to B$.

%% Lastly, we define the function $\delta : \li A \to \li A$ by $\delta = \theta_A
%% \circ \nxt$.

% The function type A \ra A' will be modeled as \sem{A} \to \li \sem{A'}

The free error domain is essential to modeling CBV computation: a term
$\Gamma \vdash M : A$ in GTLC will be modeled as a function $M :
\sem{\Gamma} \to U\li \sem{A}$ from the set denoted by $\Gamma$ to the
underlying set of the free error domain on the set denoted by $A$,
just as in a monadic semantics with monad $U\li$.

\subsection{Modeling the type structure}\label{sec:dynamic-type}
Much of the type structure of GTLC is simple to model: $\nat$ denotes
the set of natural numbers and $\times$ denotes the Cartesian product
of sets. To model the CBV function type $A \rightharpoonup A'$ we use
the CBPV decomposition $U(\sem{A} \to \li \sem{A'})$ where $A \to B$
is the obvious point-wise algebraic structure on the set of functions
from $A$ to $UB$.

The final type to model is the the dynamic type $\dyn$.  In the style
of Scott, a classical domain theoretic model for $\dyn$ would be given
by solving a domain equation
%
\[ D \cong \Nat + (D \times D) + U(D \to \li D), \]
%
representing the fact that dynamically typed values can be numbers,
pairs or CBV functions. This equation does not have inductive or
coinductive solutions due to the negative occurrence of $D$ in the
domain of the function type. In classical domain theory this is
avoided by instead taking the initial algebra in a category of
embedding-projection pairs, by which we obtain an exact solution to
this equation. However, in guarded domain theory we instead replace this domain equation with a guarded domain equation.
Consider the following similar-looking equation:
%
\begin{equation}\label{eq:dyn}
D \cong \Nat + (D \times D)\, + \laterhs U(D \to \li D).
\end{equation}
%
Since the negative occurrence of $D$ is guarded under a later, we can
solve this equation by a mixture of inductive types and guarded fixed
points. Specifically, consider the parameterized inductive type
%
\[ D'\, X := \mu T. \Nat + (T \times T) + X. \]
%
Then we can construct $D$ as the unique solution to the guarded domain equation
\[ D \cong D'(\laterhs U(D \to \li D)) \]
which is a guarded equation in that all occurrences of $D$ on the right hand side are guarded by the $\laterhs$.
%
Expanding out the guarded fixed point and least fixed point property
gives us that $D$ satisfies Equation $\ref{eq:dyn}$. 
% \max{give that equation a number}.
%
We then refer to the three injections for numbers, pairs and functions
as $\inat, \itimes, \iarr$ respectively.

\subsection{Term Semantics}\label{sec:term-interpretation}

We now extend our semantics of types to a semantics of terms of
GTLC. As mentioned above, terms $x:A_1,\ldots \vdash M : A$ are
modeled as effectful functions $\sem{M}: \sem{A_1}\times \cdots \to U\li\sem{A}$
and values $x:A_1,\ldots \vdash V : A$ are also modeled as pure
functions $\sem{V} : \sem{A_1}\times\cdots \to \sem{A}$.
%
The interpretation of the typical CBV features of GTLC into a model of CBPV is
standard \cite{levy99}; the only additional part we need to account for
is the semantics of casts, shown in Figure \ref{fig:term-semantics}.
%
%% Much of the semantics is similar to a normal call-by-value denotational
%% semantics, so we focus only on the cast semantics. We interpret types as sets;
%% the interpretation of types is given in Figure \ref{fig:type-interpretation}.
%% Contexts $\Gamma = x_1 \colon A_1, \dots, x_n \colon A_n$ are interpreted as the
%% product $\sem{A_1} \times \cdots \times \sem{A_n}$. The semantics of the dynamic
%% type $\dyn$ is the set $D$ introduced in Section \ref{sec:dynamic-type}. The
%% product type $A \times A'$ is interpreted as the Cartesian product of the
%% denotations of $A$ and $A'$. The function type $A \ra A'$ is interpreted as the
%% set of functions from $\sem{A}$ to $\li (\sem {A'})$.
%
%% The interpretation of a value $\hasty {\Gamma} V A$ is a function from
%% $\sem{\Gamma}$ to $\sem{A}$. Likewise, a term $\hasty {\Gamma} M {{A}}$ is
%% interpreted as a function from $\sem{\Gamma}$ to $\li \sem{A}$.
Following the CBPV treatment of gradual typing given by
New-Licata-Ahmed, an upcast $\upc c$ where $c : A \ltdyn A'$ is
interpreted as a pure function $\sem{\upc c} :\sem{A} \to \sem{A'}$ whereas a
downcast $\dnc c$ is interpreted as a homomorphism $\sem{\dnc c} :
\li\sem{A'} \multimap \li\sem{A}$.
%% By the universal property of $\li$, this is determined by a function $\sem{A'} \to U\li\sem{A}$ and
%% We use $\text{ext}$ to go from the former to the latter in the definitions of the downcasts.
We define the semantics of upcasts and downcasts simultaneously by
recursion over type precision derivations.
%
The reflexivity casts are given by identities, and the transitivity
casts by composition. The upcasts for products, and the downcasts for
functions are given by the functorial actions of the type constructors
on the casts for the subformulae.
%
The \emph{up}casts for functions and similarly the \emph{down}casts
for products, on the other hand, are more complex.
%
For these, we use not the ordinary functorial action of type
constructors, but an action we call the \emph{Kleisli} action.

The Kleisli action of type constructors can be defined in any CBPV
model. First, we can define the Kleisli category of value types
$\calV_k$ to have value types as objects, but have morphisms
$\calV_k(A,A') = \calE(FA,FA')$. Similarly, we can define a Kleisli
category of computation types $\calE_k$ to have computation types as
objects, but have morphisms $\calE_k(B,B') = \calV(UB,UB')$. The
intuition is that these are the ``effectful'' morphisms between
value/computation types, whereas the morphisms of $\calV$ and $\calE$ are
pure morphisms and homomorphisms, respectively. Then every CBPV type constructor $F,U,\times,\to$
has in addition to its usual functorial action on pure morphisms/homomorphisms
an action in each argument on Kleisli morphisms. So for
instance, the function construction is functorial in pure morphisms/homomorphisms
$\to : \op{\calV} \times \calE \to \calE$ but on Kleisli
morphisms what we have is for each computation type $B$ a functorial
action $-\to B : \calV_k^{op} \to \calE_k$ given by $-\tok B$ on
objects and for each value type a functorial action $A \tok - :
\calE_k \to \calE_k$. Similarly we get two actions $A \timesk -$ and
$-\timesk A'$ on Kleisli morphisms between value types. In these two
cases we do not get a bifunctorial action because the two Kleisli
actions do not commute past each other, i.e., in general $(A_l'
\timesk f_r \circ f_l \timesk A_r) \neq (f_l \timesk A_r' \circ A_l
\timesk f_r)$.
%
% EXTENDED VERSION 
% The full definitions of the Kleisli actions are included in Appendix
% \ref{sec:kleisli-actions}.
%
% CONFERENCE VERSION
%
The full definitions of the Kleisli actions are included in the appendix of the
extended version of this paper \cite{gtt-sgdt-extended-version}.

Lastly, we have the upcasts and downcasts for the injections into the dynamic type, which
are the core primitive casts. The upcasts are simply the injections
themselves, except the function case which must include a $\nxt$ to
account for the fact that the functions are under a later in the
dynamic type. The downcasts are similar in that on values
they pattern match on the input and return it if it is of the correct
type, otherwise erroring. Again, the function case is slightly
different in that if the input is in the function case, then it is
actually only a function available later, and so we must insert a
``think'' in order to return it.

% The upcast for $c_i \ra c_o$ and the downcast for $c_1 \times c_2$ make use of
% \emph{Kleisli functors} $\tok$ and $\timesk$.

%% \eric{Introduce Kleisli categories and functors}

%% Recall the definition of type precision derivations given in Figure
%% \ref{fig:typrec}. The semantics of the up- and downcasts for a type precision
%% derivation $c$ are defined by induction on $c$.
%% %
%% For $r(A)$ the up- and downcasts are simply the identity function. 
%% %
%% For the composition $c \comp c'$ we compose the cast for $c$ and the cast for
%% $c'$ as functions.
%% %
%% For $c_i \ra c_o$ we apply the casts for $c_i$ and $c_o$ in the domain and
%% codomain respectively. More concretely, for the upcast we are given a function
%% $V_f : A_i \to \li A_o$ and we must define a function $A_i' \to \li A_o'$. The
%% function first downcasts its argument according to $c_i$, resulting in an
%% element of $\li A_i$. It then applies $\ext{V_f}{}$ to this value to obtain an
%% element of $\li A_o$. Finally, it applies the upcast of $c_o$ via the functorial
%% action of the lift monad, obtaining an element of $\li A_o'$ as needed. For the
%% downcast from $A_i' \to \li A_o'$ to $A_i \to \li A_o$, the resulting function
%% first applies the upcast by $c_i$ to its argument, then applies the original
%% function, and finally applies the downcast by $c_o$ to the result.
%% %
%% Likewise, in the upcast for $c_1 \times c_2$, we apply the cast for $c_1$ on the
%% left and the cast for $c_2$ on the right.

%% The ``base cases'' for the casts are $\inat$, $\itimes$, and $\iarr$. Recall
%% that $D$ is isomorphic to $\Nat\, + (D \times D)\, + \laterhs (D \to \li D)$
%% (say that the sum is left-associative).
%% %
%% For $\inat$, the upcast is simply $\inl \circ \inl$. The downcast has type $D
%% \to \li D$ and performs a case inspection on the sum type. If it is a natural
%% number $n$, then we return $\eta\, n$. Otherwise, we return $\mho$, modeling
%% the fact that a run-time error occurs.
%% %
%% For $\itimes$, the upcast is $\inl \circ \inr$, and the downcast performs a case
%% inspection analogously to the natural number downcast.
%% %
%% % TODO explain this further
%% For $\iarr$, the upcast is given by $\inr \circ \nxt$. The downcast performs a
%% case inspection, and in the $\inr$ case, it uses a $\theta$ in order to gain
%% access to the function under the $\later$.


%
% TODO write this out explicitly?

% TODO should we include function casts?
%% \begin{figure*}
%%   \begin{align*}
%%     \sem{\nat} &= \Nat \\
%%     \sem{\dyn} &= D \\
%%     \sem{A \times A'} &= \sem{A} \times \sem{A'} \\ 
%%     \sem{A \ra A'} &= \sem{A} \To \li \sem{A'} \\
%%   \end{align*}
%%   \caption{Interpretation of types}
%%   \label{fig:type-interpretation}
%% \end{figure*}
\begin{figure*}
  \begin{minipage}{0.3\textwidth}
    \begin{footnotesize}
  \begin{align*}
    % upcasts
    \sem{\upc{r(A)}} &= \id_{\sem{A}} \\
    \sem{\upc{(c \comp c')}} &= \sem{\upc{c'}} \circ \sem{\upc{c}} \\
    \sem{\upc{(c_i \ra c_o)}} &= (\sem{\dnc {c_i}} \tok \li\sem{A_o'})\circ (\sem{A_i} \tok U\li(\sem{\upc {c_o}}))\\
    \sem{\upc{(c_1 \times c_2)}} &= \sem{\upc{c_1}} \times \sem{\upc{c_2}}\\
    \sem{\upc{\inat}} &= \inat\\
    \sem{\upc{\itimes}} &= \itimes\\
    \sem{\upc{\iarr}} &= \iarr \circ \nxt\\
    % \sem{\zro}         &= \lambda \gamma . 0 \\
    % \sem{\suc\, V}     &= \lambda \gamma . (\sem{V}\, \gamma) + 1 \\
    % \sem{x \in \Gamma} &= \lambda \gamma . \gamma(x) \\
    % \sem{\lda{x}{M}}   &= \lambda \gamma . \lambda a . \sem{M}\, (*,\, (\gamma , a))  \\
    % \sem{V_f\, V_x}    &= \lambda \gamma . {({(\sem{V_f}\, \gamma)} \, {(\sem{V_x}\, \gamma)})} \\
    % \sem{\err_B}       &= \lambda \gamma . \mho \\
    %
    % downcasts
    \sem{\dnc{r(A)}} &= \id_{\li \sem{A}} \\
    \sem{\dnc{(c \comp c')}} &= \sem{\dnc{c}} \circ \sem{\dnc{c'}} \\
    \sem{\dnc{(c_i \ra c_o)}} &= U(\sem{\upc {c_i}} \to \sem{\dnc {c_o}})\\
    \sem{\dnc{(c_1 \times c_2)}} &= (\sem{\dnc{c_1}} \timesk \sem{A_2}) \circ (\sem{A_1'} \timesk \sem{\dnc{c_2}}) \\
    \sem{\dnc{\inat}} &= (
      \lambda V_d . \text{case $({V_d})$ of }
      \{ \inat\,n \to \eta\, n
         \alt \text{otherwise} \to \mho \})^\dagger \\
    \sem{\dnc{\itimes}} &= (
      \lambda V_d . \text{case $({V_d})$ of }
      \{ \itimes(d_1, d_2) \to \eta\, (d_1, d_2)
         \alt \text{otherwise} \to \mho \})^\dagger \\
    \sem{\dnc{\iarr}} &= (
      \lambda V_d . \text{case $({V_d})$ of }
      \{ \iarr \tilde{f} \to \theta_t\, (\eta (\tilde{f}_t))
         \alt \text{otherwise} \to \mho \})^\dagger \\
    % \sem{\ret\, V}       &= \lambda \gamma . \eta\, \sem{V} \\
    % \sem{\bind{x}{M}{N}} &= \lambda \delta . \ext {(\lambda x . \sem{N}\, (\delta, x))} {\sem{M}\, \delta} \\
  \end{align*}
    \end{footnotesize}
  \end{minipage}
  \caption{Semantics of casts}
  \label{fig:term-semantics}
\end{figure*}

\subsection{Extracting a well-behaved big-step semantics}\label{sec:big-step-term-semantics}

% \max{TODO: Eric needs to add a discussion of adequacy/clock stuff here}
% \eric{Check this}

We now define from the above term model a ``big-step'' semantics. More
concretely, our goal is to define a partial function 
$-\Downarrow : \{M \,|\, \cdot \vdash M : \nat \} \rightharpoonup \mathbb{N} + {\mho}$.

To begin, we must first discuss another aspect of guarded type theory. The
constructions of guarded type theory ($\later$, $\nxt$, and $\fix$) we have been
using may be indexed by objects called \emph{clocks} \cite{atkey-mcbride2013}. A clock intuitively serves
as a reference relative to which steps are counted. For instance, given a clock
$k$ and type $X$, the type $\later^k X$ represents a value of type $X$ one unit
of time in the future according to clock $k$.
%
Up to this point, all uses of guarded constructs have been indexed by a single
clock $k$. In particular, we have for each clock $k$ a type $\li^k X$. The
notion of \emph{clock quantification} allows us to pass from the guarded setting
to the usual set-theoretic world. Clock quantification enables us to encode
coinductive types using guarded recursion. That is, given a type $A$ with a free
variable $k : \Clock$, we can form the type $A^{gl} := \forall k. A$ (here, $gl$ stands for ``global'').

A functor $F \colon \mathsf{Type} \to \mathsf{Type}$ is said to \emph{commute
with clock quantification} if for all $X : \Clock \to \mathsf{Type}$, the
canonical map $F(\forall k. X_k) \to \forall k. F(X_k)$ is an equivalence \cite{kristensen-mogelberg-vezzosi2022},
where we write $X_k$ for the application of clock $k$ to $X$.
%
Given a functor $F$ that commutes with clock quantification, if $A$ is a guarded
recursive type satisfying $A \cong F(\later^k A)$, then the type $A^{gl}$ has a
final $F$-coalgebra structure (see Theorem 4.3 of Kristensen et al. \cite{kristensen-mogelberg-vezzosi2022}). 

Consider the functor $F(X) = \mathbb{N} + {\mho} + X$. By the definition of the
guarded lift, we have that
% 
$\li^k \mathbb{N} 
  \cong \mathbb{N} + {\mho} + \later^k (\li \mathbb{N}) 
  \cong F(\later \li^k \mathbb{N})$.
%
Furthermore, it can be shown that the functor $F$ commutes with clock
quantification. Thus, the type $\li^{gl} \mathbb{N} := \forall k. \li^k
\mathbb{N}$ is a final $F$-coalgebra. In fact, $\li^{gl}$ is isomorphic to a
more familiar coinductive type.
%
Given a type $Y$, Capretta's \emph{delay monad} \cite{lmcs:2265},
which we write as $\text{Delay}(Y)$, is defined as the coinductive type
generated by $\tnow : Y \to \delay(Y)$ and $\tlater : \delay(Y) \to \delay(Y)$.
We have that $\delay (\mathbb{N} + {\mho})$ is a final coalgebra for the functor
$F$ defined above. This means $\li^{gl} \mathbb{N}$ is isomorphic to
$\delay(\mathbb{N} + {\mho})$. We write $\alpha$ to denote this isomorphism.

Given $d : \delay(\mathbb{N} + {\mho})$, we define a notion of termination in
$i$ steps with result $n_? \in \mathbb{N} + {\mho}$, written $d \da^i n_?$.
We define $d \da^i n_?$ inductively by the rules
$(\tnow\, n_?) \da^0 n_?$ and $(\tlater\, d) \da^{i+1} n_?$ if $d \da^i n_?$.
From this definition, it is clear that if there is an $i$
such that $d \da^i n_?$, then this $i$ is unique. 
% Furthermore, from the proof that
% $d$ terminates in $i$ steps, we can extract the result with which $d$
% terminates. This is defined by a straightforward induction on the proof that $d \da^i$.
Using this definition of termination, we define a partial function 
%
$-\Downarrow^\text{Delay} \colon \delay (\mathbb{N} + {\mho}) \rightharpoonup \mathbb{N} + {\mho}$
%
by existentially quantifying over $i$ for which $d \da^i n_?$. That is, we
define $d \Downarrow^\text{Delay} \,= n_?$ if $d \da^i n_?$ for some (necessarily
unique) $i$, and $d \Downarrow^\text{Delay}$ is undefined otherwise.

Now consider the global version of the term semantics, $\sem{\cdot}^{gl} \colon
\{M \,|\, \cdot \vdash M : \nat \} \to \li^{gl} \mathbb{N}$, defined by
$\sem{M}^{gl} := \lambda (k : \Clock) .\sem{M}$. Composing this with the
isomorphism $\alpha : \li^{gl} \mathbb{N} \cong \delay(\mathbb{N} + {\mho})$ and
the partial function $-\Downarrow^\text{Delay}$ yields the desired partial
function
%
$-\Downarrow \colon \{M \,|\, \cdot \vdash M : \nat \} \rightharpoonup \mathbb{N} + {\mho}$.
%
It is then straightforward to see that this big-step semantics respects the
equational theory and that the denotations of the diverging term $\Omega$, the
error term $\mho$, and a syntactic natural number value $n$ are all distinct.
